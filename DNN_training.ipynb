{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.layers import dropout\n",
    "from tensorflow.contrib.layers import batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "if os.name=='nt':\n",
    "    parentDir= 'C:/Users/Administrator.NBJXUEJUN-LI/Desktop/project/ncpltnpj/'\n",
    "else:\n",
    "    parentDir= '/Users/snakepointid/Documents/project/cpltnpj/'\n",
    "UserTargdayLabel =pd.read_csv(parentDir+'save/DNN_feeds.csv',header=0,encoding='gbk' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #perpare datas\n",
    "predData  = UserTargdayLabel[UserTargdayLabel['label']==-1]\n",
    "trainData = UserTargdayLabel[UserTargdayLabel['labelday']!='2016-04-11']\n",
    "testData  = UserTargdayLabel[UserTargdayLabel['labelday']=='2016-04-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX     = np.array(trainData.ix[:,3:],dtype=np.float32)\n",
    "trainy     = np.array(trainData.ix[:,2],dtype=np.float32)\n",
    "trainy     = trainy.reshape((len(trainy),1))\n",
    "\n",
    "testX      = np.array(testData.ix[:,3:],dtype=np.float32)\n",
    "testy      = np.array(testData.ix[:,2],dtype=np.float32)\n",
    "testy      = testy.reshape((len(testy),1))\n",
    "\n",
    "predX      = np.array(predData.ix[:,3:],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.088514128393867131, 0.010754054767468007)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.sum()/len(trainy),testy.sum()/len(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set neurons' dimemsions\n",
    "n_inputs  = len(trainX[0])\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 300\n",
    "n_hidden3 = 200\n",
    "n_hidden4 = 100\n",
    "n_outpus  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_training = tf.placeholder_with_default(False, shape=(), name='is_training') \n",
    "keep_prob = 0.5\n",
    "bn_params={\n",
    "    'is_training':is_training,\n",
    "    'decay':0.99,\n",
    "    'updates_collections':None\n",
    "}\n",
    "with tf.name_scope(\"dnn\"):  \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, n_outpus])\n",
    "    X_drop = dropout(X, keep_prob, is_training=is_training)\n",
    "    hidden1 = fully_connected(X_drop,  n_hidden1, scope=\"hidden1\",activation_fn=tf.nn.elu,normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\",activation_fn=tf.nn.elu,normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    hidden3 = fully_connected(hidden2, n_hidden3, scope=\"hidden3\",activation_fn=tf.nn.elu,normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    hidden4 = fully_connected(hidden3, n_hidden4, scope=\"hidden4\",activation_fn=tf.nn.elu,normalizer_fn=batch_norm,normalizer_params=bn_params)\n",
    "    logits  = fully_connected(hidden4, n_outpus,  scope=\"outputs\",activation_fn=None)\n",
    "    actlogits = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 3\n",
    "batch_size = 10000\n",
    "batch_num = len(trainX) // batch_size+1\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):  \n",
    "        for batch in range(batch_num):\n",
    "            X_batch, y_batch = trainX[batch*batch_size:(batch+1)*batch_size],trainy[batch*batch_size:(batch+1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch,y:y_batch,is_training:True})\n",
    "         \n",
    "        train_out = logits.eval(feed_dict={X: trainX,y:trainy})\n",
    "        test_out  = logits.eval(feed_dict={X: testX, y:testy})\n",
    "        print (roc_auc_score(trainy,train_out),roc_auc_score(testy,test_out))\n",
    "    test_out  = actlogits.eval(feed_dict={X: testX, y:testy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plotF1score(score,y):\n",
    "    scorePs = np.arange(100)/100\n",
    "    F1s = np.zeros(100,dtype=np.float32)\n",
    "    for i in range(100):   \n",
    "        scoreP = scorePs[i]\n",
    "        TP = np.equal(y[score>scoreP],1).astype('f').sum()\n",
    "        pred_posi_num = (score>scoreP).astype('f').sum()\n",
    "        all_posi_num  = y.sum()\n",
    "        Recall  = TP/all_posi_num\n",
    "        Precise = TP/pred_posi_num\n",
    "        F1s[i] = 6*Recall*Precise/(5*Recall+Precise)\n",
    "    plt.plot(scorePs,F1s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotF1score(test_out,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
